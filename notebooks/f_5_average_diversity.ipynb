{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9feeee35-ba35-460e-a1ed-9b4015b47dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kr8cht_review_anonymous/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "2025-10-16 00:40:02 INFO: === f_5_average_diversity started ===\n",
      "\n",
      "Linear models (chain_lr, local_lasso)\n",
      "                      Model                0               10               20               50              100              200              400\n",
      "                   chain_lr            0.689            0.674            0.668            0.674            0.685            0.685            0.685\n",
      "                local_lasso            0.705            0.690            0.688            0.678            0.679            0.685            0.698\n",
      "Avg. diversity (1−cos) [E5] 0.164278 (+0.0%) 0.164011 (-0.2%) 0.164453 (+0.1%) 0.165774 (+0.9%) 0.167564 (+2.0%) 0.169500 (+3.2%) 0.171336 (+4.3%)\n",
      "Spearman ρ (AvgDiv vs ΔRRMSE), linear: rho = -0.600, p = 0.208\n",
      "\n",
      "Tree-based models (local_rf, global_rf, chain_rf)\n",
      "                      Model                0               10               20               50              100              200              400\n",
      "                   local_rf            0.839            0.834            0.792            0.811            0.823            0.816            0.780\n",
      "                  global_rf            0.877            0.859            0.839            0.824            0.854            0.855            0.824\n",
      "                   chain_rf            0.833            0.798            0.778            0.792            0.790            0.788            0.772\n",
      "Avg. diversity (1−cos) [E5] 0.164278 (+0.0%) 0.164011 (-0.2%) 0.164453 (+0.1%) 0.165774 (+0.9%) 0.167564 (+2.0%) 0.169500 (+3.2%) 0.171336 (+4.3%)\n",
      "Spearman ρ (AvgDiv vs ΔRRMSE), tree-based: rho = 0.486, p = 0.329\n",
      "\n",
      "Monotonicity check for AvgDiv: FAIL (first decrease at %= 10).\n",
      "2025-10-16 00:40:02 INFO: === f_5_average_diversity completed ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kr8cht_review_anonymous/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "f_5_average_diversity.ipynb\n",
    "───────────────────────────────────────────────────────────────────────────────\n",
    "Average diversity vs augmentation size (fold-agnostic) and correlation with\n",
    "performance gains for linear and tree-based MTRs.\n",
    "\n",
    "This script:\n",
    "1) Computes **Average diversity** of the actual training set geometry used at each\n",
    "   augmentation level, measured as the **mean pairwise cosine dissimilarity**\n",
    "   (1 − cosine) in the **e5_base** embedding space. We use a fold-agnostic setup:\n",
    "   the set is **all 96 seeds** plus the first K synthetics from the ordered\n",
    "   Script-A finals (method = `gemma`).\n",
    "   • Efficient computation uses a streaming identity to avoid n×n Gram matrices:\n",
    "     AvgDiv = 1 − (‖∑u_i‖² − n) / (n(n − 1)) with unit vectors u_i.\n",
    "2) Loads per-fold RRMSE results from Script-C (student scoring) and aggregates the\n",
    "   **global median RRMSE** (median over all folds×domains) for the baseline (0%)\n",
    "   and each augmentation size.\n",
    "3) Builds two report tables (CSV):\n",
    "   • Linear models: {chain_lr, local_lasso}.\n",
    "   • Tree-based models: {local_rf, global_rf, chain_rf}.\n",
    "   Each table mirrors the article’s layout (columns = {0,10,20,50,100,200,400}),\n",
    "   with model rows showing global-median RRMSE and a bottom row showing\n",
    "   **Avg. diversity (1−cos) [E5]** as absolute values, with **relative change vs 0%**\n",
    "   in parentheses.\n",
    "4) Computes **Spearman ρ** between AvgDiv and **ΔRRMSE** (baseline − full) for\n",
    "   the linear group and for the tree-based group (family-level Δ is the mean of\n",
    "   member models at each %K).\n",
    "5) Performs a **monotonicity check** for AvgDiv across {0,10,20,50,100,200,400}.\n",
    "\n",
    "Inputs:\n",
    "- outputs/e_1_synth_augmentation/g_final_n3072_gemma.csv\n",
    "- outputs/results/e5_base_vectors.npy (or fallback to outputs/e_3_student_scoring/cache/X_seed_e5_base.npy)\n",
    "- outputs/e_2_teacher_labeling/cache/synth_embeds/g_final_n3072_gemma__e5_base.npy\n",
    "  and companion index CSV (or rebuilt on the fly if missing)\n",
    "- outputs/e_3_student_scoring/results/\n",
    "    rrmse_perfold_e5_base__{reg}__gemma__pct{P}_K{K}__Mmax{M}__baseline.csv\n",
    "    rrmse_perfold_e5_base__{reg}__gemma__pct{P}_K{K}__Mmax{M}__full.csv\n",
    "\n",
    "Outputs:\n",
    "- outputs/f_final_report/f_5_average_diversity/\n",
    "    run.log\n",
    "    tables/\n",
    "      linear_rrmse_plus_diversity.csv\n",
    "      tree_rrmse_plus_diversity.csv\n",
    "      diversity_values.csv\n",
    "    stats/\n",
    "      spearman_and_monotonicity.txt\n",
    "\n",
    "Notes:\n",
    "- Embedding space is fixed to **e5_base** for primary reporting.\n",
    "- Method is fixed to **gemma** (match your Script-A/Script-C runs).\n",
    "- Augmentation sizes follow the percent-based protocol used in Script-C:\n",
    "  %K ∈ {10, 20, 50, 100, 200, 400} with K = round(% × 96 / 100) = {10,19,48,96,192,384}.\n",
    "- The baseline (0%) diversity is computed on the 96 seeds only.\n",
    "- The baseline RRMSE shown in column 0 is taken from the baseline variant files\n",
    "  (these are seeds-only predictions; Script-C already writes them per %K for\n",
    "  naming symmetry and they should be identical across %K).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Imports\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "try:\n",
    "    # Optional, only needed if synth caches are missing and we need to rebuild.\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "except Exception:\n",
    "    SentenceTransformer = None  # guard for environments where not installed\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Paths & constants (same style as other scripts)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def project_root(marker: str = \"LICENSE\") -> Path:\n",
    "    here = Path.cwd().resolve()\n",
    "    for d in (here, *here.parents):\n",
    "        if (d / marker).is_file():\n",
    "            return d\n",
    "    return Path.cwd().resolve()\n",
    "\n",
    "ROOT = project_root()\n",
    "os.chdir(ROOT)\n",
    "\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "OUT_DIR  = ROOT / \"outputs\" / \"f_final_report\" / \"f_5_average_diversity\"\n",
    "TABLES_DIR = OUT_DIR / \"tables\"\n",
    "STATS_DIR  = OUT_DIR / \"stats\"\n",
    "\n",
    "G1_DIR  = ROOT / \"outputs\" / \"e_1_synth_augmentation\"\n",
    "G2_DIR  = ROOT / \"outputs\" / \"e_2_teacher_labeling\"\n",
    "G3_DIR  = ROOT / \"outputs\" / \"e_3_student_scoring\"  \n",
    "RES_DIR = G3_DIR / \"results\"\n",
    "\n",
    "for p in (TABLES_DIR, STATS_DIR):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LOG_FILE = OUT_DIR / \"run.log\"\n",
    "for h in list(logging.root.handlers):\n",
    "    logging.root.removeHandler(h)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(str(LOG_FILE), mode=\"a\", encoding=\"utf-8\"),\n",
    "        logging.StreamHandler(getattr(__import__('sys'), \"__stdout__\", None) or __import__('sys').stdout),\n",
    "    ],\n",
    "    force=True,\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Config\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "METHOD = \"gemma\"\n",
    "EMB_KEY = \"e5_base\"\n",
    "EMBEDDING_REPO = \"embaas/sentence-transformers-multilingual-e5-base\"\n",
    "\n",
    "N_SEEDS = 96\n",
    "PCTS = [10, 20, 50, 100, 200, 400]\n",
    "PCT_TO_K = {p: max(1, int(round(p * N_SEEDS / 100.0))) for p in PCTS}  # {10:10,20:19,48,96,192,384}\n",
    "K_LIST = [PCT_TO_K[p] for p in PCTS]\n",
    "COLS = [0] + PCTS  # table columns (0% baseline + augmented levels)\n",
    "\n",
    "TARGET_COLS = [f\"rrmse_domain{i}\" for i in range(1, 15)]  # columns in per-fold files\n",
    "\n",
    "# Model groups (map file keys → display names to match article style)\n",
    "LINEAR_MODELS = [\"chain_ERCcv_lr\", \"local_lasso\"]\n",
    "TREE_MODELS   = [\"local_rf\", \"global_rf\", \"chain_ERCcv_rf\"]\n",
    "DISPLAY_NAME = {\n",
    "    \"chain_ERCcv_lr\": \"chain_lr\",\n",
    "    \"local_lasso\": \"local_lasso\",\n",
    "    \"local_rf\": \"local_rf\",\n",
    "    \"global_rf\": \"global_rf\",\n",
    "    \"chain_ERCcv_rf\": \"chain_rf\",\n",
    "}\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Embedding utilities (normalized vectors and streaming diversity)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _unit_rows(X: np.ndarray) -> np.ndarray:\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    nrm = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    nrm = np.clip(nrm, 1e-9, None)\n",
    "    return X / nrm\n",
    "\n",
    "\n",
    "def avg_div_from_sum(s: np.ndarray, n: int) -> float:\n",
    "    \"\"\"Average pairwise (1 − cosine) using only the sum of unit vectors.\n",
    "    AvgDiv = 1 − (||sum(u_i)||^2 − n) / (n(n−1)).\n",
    "    \"\"\"\n",
    "    if n <= 1:\n",
    "        return 0.0\n",
    "    s2 = float(np.dot(s, s))\n",
    "    return 1.0 - (s2 - n) / (n * (n - 1))\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Loading seeds and synthetics (reusing Script-C conventions where possible)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def load_seed_vectors_e5() -> np.ndarray:\n",
    "    \"\"\"Load seed sentence embeddings for EMB_KEY. Prefer Script-C cache.\n",
    "    Tries outputs/results/e5_base_vectors.npy, then e_3_student_scoring/cache.\n",
    "    \"\"\"\n",
    "    pref = ROOT / \"outputs\" / \"results\" / f\"{EMB_KEY}_vectors.npy\"\n",
    "    if pref.exists():\n",
    "        X = np.load(pref).astype(np.float32, copy=False)\n",
    "        if X.shape[0] != N_SEEDS:\n",
    "            log.warning(\"Seed vectors found but unexpected row count: %s\", X.shape)\n",
    "        return X\n",
    "    alt = G3_DIR / \"cache\" / f\"X_seed_{EMB_KEY}.npy\"\n",
    "    if alt.exists():\n",
    "        X = np.load(alt).astype(np.float32, copy=False)\n",
    "        return X\n",
    "    # As a last resort, rebuild via SentenceTransformer\n",
    "    if SentenceTransformer is None:\n",
    "        raise RuntimeError(\"SentenceTransformer not available to rebuild seed vectors.\")\n",
    "    log.info(\"Recomputing seed embeddings with %s …\", EMBEDDING_REPO)\n",
    "    acts = pd.read_csv(DATA_DIR / \"activities.csv\")\n",
    "    acts = acts.sort_values(\"activity_id\")\n",
    "    texts = acts[\"question\"].astype(str).tolist()\n",
    "    if len(texts) != N_SEEDS:\n",
    "        raise RuntimeError(f\"Expected {N_SEEDS} seed texts, got {len(texts)}\")\n",
    "    mdl = SentenceTransformer(EMBEDDING_REPO)\n",
    "    X = mdl.encode(texts, batch_size=64, show_progress_bar=False, convert_to_numpy=True)\n",
    "    X = X.astype(np.float32, copy=False)\n",
    "    (ROOT / \"outputs\" / \"results\").mkdir(parents=True, exist_ok=True)\n",
    "    np.save(pref, X)\n",
    "    np.save(alt, X)\n",
    "    return X\n",
    "\n",
    "\n",
    "def g1_source_csv(M: int) -> Path:\n",
    "    p = G1_DIR / f\"g_final_n{M}_{METHOD}.csv\"\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Missing Script-A source: {p}\")\n",
    "    return p\n",
    "\n",
    "\n",
    "def synth_cache_paths(M: int) -> Tuple[Path, Path]:\n",
    "    \"\"\"Return (npy, index.csv) for Script-A finals under the given embedding.\n",
    "    Uses Script-C cache layout; rebuilds if missing (requires SentenceTransformer).\n",
    "    \"\"\"\n",
    "    base_csv = g1_source_csv(M)\n",
    "    base_tag = base_csv.stem.replace(\"g_final_\", \"\")  # n{M}_{method}\n",
    "    cache_dir = G2_DIR / \"cache\" / \"synth_embeds\"\n",
    "    npy = cache_dir / f\"g_final_{base_tag}__{EMB_KEY}.npy\"\n",
    "    idx = cache_dir / f\"g_final_{base_tag}__index.csv\"\n",
    "    if npy.exists() and idx.exists():\n",
    "        return npy, idx\n",
    "    # Rebuild cache if needed\n",
    "    if SentenceTransformer is None:\n",
    "        raise FileNotFoundError(f\"Synth cache missing and no ST model to rebuild: {npy.name}\")\n",
    "    log.info(\"Building synth cache for %s, M=%d …\", METHOD, M)\n",
    "    df = pd.read_csv(base_csv)\n",
    "    if \"text\" not in df.columns:\n",
    "        raise ValueError(\"Finals CSV missing 'text' column\")\n",
    "    texts = df[\"text\"].astype(str).tolist()\n",
    "    mdl = SentenceTransformer(EMBEDDING_REPO)\n",
    "    X = mdl.encode(texts, batch_size=64, show_progress_bar=False, convert_to_numpy=True)\n",
    "    X = X.astype(np.float32, copy=False)\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    np.save(npy, X)\n",
    "    pd.DataFrame({\"text\": texts}).to_csv(idx, index=False)\n",
    "    log.info(\"✔ Saved synth cache → %s ; %s\", npy.relative_to(ROOT), idx.relative_to(ROOT))\n",
    "    return npy, idx\n",
    "\n",
    "\n",
    "def discover_M_max_for_method() -> int:\n",
    "    \"\"\"Discover available M for METHOD under G2 labels (Script-C style); pick max.\n",
    "    Fallback to 3072 if discovery fails but finals exist for that size.\n",
    "    \"\"\"\n",
    "    pats = sorted(G2_DIR.glob(f\"g2f_labels_fold00_n*_{METHOD}__{EMB_KEY}__*.csv\"))\n",
    "    M_vals = []\n",
    "    for p in pats:\n",
    "        m = re.match(rf\"g2f_labels_fold00_n(\\d+)_({METHOD})__{EMB_KEY}__.*\\\\.csv$\", p.name)\n",
    "        if m:\n",
    "            M_vals.append(int(m.group(1)))\n",
    "    if M_vals:\n",
    "        return max(M_vals)\n",
    "    # fallback if labels not present but finals exist\n",
    "    for M in (3072, 1536, 768):\n",
    "        if (G1_DIR / f\"g_final_n{M}_{METHOD}.csv\").exists():\n",
    "            return M\n",
    "    raise RuntimeError(\"Could not discover M_max; ensure Script-A/B/C outputs exist.\")\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# RRMSE aggregation utilities (global median over folds×domains)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def rrmse_file_path(reg: str, pct: int, K: int, Mmax: int, variant: str) -> Path:\n",
    "    return RES_DIR / (\n",
    "        f\"rrmse_perfold_{EMB_KEY}__{reg}__{METHOD}__pct{pct}_K{K}__Mmax{Mmax}__{variant}.csv\"\n",
    "    )\n",
    "\n",
    "\n",
    "def global_median_rrmse_from_file(p: Path) -> float:\n",
    "    df = pd.read_csv(p)\n",
    "    dom_cols = [c for c in df.columns if c.startswith(\"rrmse_domain\")]\n",
    "    if dom_cols:\n",
    "        arr = df[dom_cols].to_numpy(dtype=np.float32).ravel()\n",
    "        return float(np.median(arr))\n",
    "    # Fallback: median over per-fold medians (approximation)\n",
    "    if \"median_rrmse_fold\" in df.columns:\n",
    "        return float(np.median(df[\"median_rrmse_fold\"].to_numpy(dtype=np.float32)))\n",
    "    raise ValueError(f\"{p.name}: no RRMSE columns found.\")\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Monotonicity check\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def monotone_non_decreasing(values: List[float], tol: float = 1e-9) -> Tuple[bool, int | None]:\n",
    "    \"\"\"Return (ok, first_violation_index). Index refers to COLS order.\n",
    "    Accepts tiny numerical noise via tol.\n",
    "    \"\"\"\n",
    "    for i in range(1, len(values)):\n",
    "        if values[i] + tol < values[i - 1]:\n",
    "            return False, i\n",
    "    return True, None\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Main\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def main():\n",
    "    log.info(\"=== f_5_average_diversity started ===\")\n",
    "\n",
    "    # 1) Load seed vectors and compute sum of unit vectors\n",
    "    X_seed = load_seed_vectors_e5()\n",
    "    U_seed = _unit_rows(X_seed)\n",
    "    s_seed = U_seed.sum(axis=0)\n",
    "    n_seed = U_seed.shape[0]\n",
    "    if n_seed != N_SEEDS:\n",
    "        log.warning(\"Seed vector count = %d (expected %d)\", n_seed, N_SEEDS)\n",
    "\n",
    "    # 2) Load synthetics at M_max and build prefix sums over unit vectors\n",
    "    Mmax = discover_M_max_for_method()\n",
    "    npy, idx = synth_cache_paths(Mmax)\n",
    "    X_syn = np.load(npy).astype(np.float32, copy=False)\n",
    "    U_syn = _unit_rows(X_syn)\n",
    "    # prefix sums S[k] = sum of first k rows (1-based logic handled below)\n",
    "    S_prefix = np.vstack([np.zeros((1, U_syn.shape[1]), dtype=np.float32), np.cumsum(U_syn, axis=0)])\n",
    "\n",
    "    # 3) Diversity per column (0 + augmented levels)\n",
    "    div_abs: Dict[int, float] = {}\n",
    "    div_rel: Dict[int, float] = {}\n",
    "\n",
    "    # 0% baseline: seeds only\n",
    "    d0 = avg_div_from_sum(s_seed, n_seed)\n",
    "    div_abs[0] = d0\n",
    "\n",
    "    for pct in PCTS:\n",
    "        K = PCT_TO_K[pct]\n",
    "        s = s_seed + S_prefix[K]\n",
    "        n = n_seed + K\n",
    "        div_abs[pct] = avg_div_from_sum(s, n)\n",
    "\n",
    "    for c in COLS:\n",
    "        div_rel[c] = 0.0 if c == 0 else 100.0 * (div_abs[c] - d0) / max(d0, 1e-12)\n",
    "\n",
    "    # 4) Build RRMSE tables (global median) for linear and tree-based models\n",
    "    def build_table_for(models: List[str]) -> pd.DataFrame:\n",
    "        rows = []\n",
    "        for reg in models:\n",
    "            disp = DISPLAY_NAME.get(reg, reg)\n",
    "            row = {\"Model\": disp}\n",
    "            # Column 0 from any baseline file (use first PCTS entry)\n",
    "            p0 = rrmse_file_path(reg, PCTS[0], PCT_TO_K[PCTS[0]], Mmax, variant=\"baseline\")\n",
    "            if not p0.exists():\n",
    "                raise FileNotFoundError(f\"Baseline file missing: {p0.name}\")\n",
    "            row[0] = global_median_rrmse_from_file(p0)\n",
    "            # Augmented columns from FULL files\n",
    "            for pct in PCTS:\n",
    "                p_full = rrmse_file_path(reg, pct, PCT_TO_K[pct], Mmax, variant=\"full\")\n",
    "                if not p_full.exists():\n",
    "                    raise FileNotFoundError(f\"Full file missing: {p_full.name}\")\n",
    "                row[pct] = global_median_rrmse_from_file(p_full)\n",
    "            rows.append(row)\n",
    "        # Diversity bottom row with absolute value and (+rel%) per cell\n",
    "        div_row = {\"Model\": \"Avg. diversity (1−cos) [E5]\"}\n",
    "        for c in COLS:\n",
    "            div_row[c] = f\"{div_abs[c]:.6f} ({div_rel[c]:+.1f}%)\"\n",
    "        df = pd.DataFrame(rows)\n",
    "        df = df[[\"Model\", *COLS]]\n",
    "        df = pd.concat([df, pd.DataFrame([div_row])], axis=0, ignore_index=True)\n",
    "        return df\n",
    "\n",
    "    df_linear = build_table_for(LINEAR_MODELS)\n",
    "    df_tree   = build_table_for(TREE_MODELS)\n",
    "\n",
    "    # 5) Spearman ρ between AvgDiv and ΔRRMSE per family (mean Δ across models)\n",
    "    # Compute Δ per model at each pct (baseline − full). Baseline: use column 0 values.\n",
    "    def deltas_by_family(models: List[str]) -> List[float]:\n",
    "        # Gather Δ for each model×pct, then average across models for each pct\n",
    "        deltas_per_pct: Dict[int, List[float]] = {pct: [] for pct in PCTS}\n",
    "        # Build a temp lookup from the just-built tables\n",
    "        tmp = build_table_for(models)\n",
    "        tmp = tmp[tmp[\"Model\"] != \"Avg. diversity (1−cos) [E5]\"]\n",
    "        base_by_model = {row[\"Model\"]: float(row[0]) for _, row in tmp.iterrows()}\n",
    "        for _, row in tmp.iterrows():\n",
    "            model = row[\"Model\"]\n",
    "            base_val = base_by_model[model]\n",
    "            for pct in PCTS:\n",
    "                deltas_per_pct[pct].append(base_val - float(row[pct]))\n",
    "        return [float(np.mean(deltas_per_pct[p])) for p in PCTS]\n",
    "\n",
    "    deltas_lin = deltas_by_family(LINEAR_MODELS)\n",
    "    deltas_tree = deltas_by_family(TREE_MODELS)\n",
    "\n",
    "    # Spearman uses the six augmented points; AvgDiv sequence excludes the 0% cell\n",
    "    div_series = [div_abs[p] for p in PCTS]\n",
    "    rho_lin, p_lin = spearmanr(div_series, deltas_lin)\n",
    "    rho_tree, p_tree = spearmanr(div_series, deltas_tree)\n",
    "\n",
    "    # 6) Monotonicity check for AvgDiv across [0,10,20,50,100,200,400]\n",
    "    div_all = [div_abs[c] for c in COLS]\n",
    "    ok, idx = monotone_non_decreasing(div_all)\n",
    "\n",
    "    # 7) Save outputs\n",
    "    out_linear = TABLES_DIR / \"linear_rrmse_plus_diversity.csv\"\n",
    "    out_tree   = TABLES_DIR / \"tree_rrmse_plus_diversity.csv\"\n",
    "    out_divcsv = TABLES_DIR / \"diversity_values.csv\"\n",
    "\n",
    "    df_linear.to_csv(out_linear, index=False)\n",
    "    df_tree.to_csv(out_tree, index=False)\n",
    "    div_df = pd.DataFrame({\n",
    "        \"pct\": COLS,\n",
    "        \"K\": [0] + K_LIST,\n",
    "        \"avg_div\": div_all,\n",
    "        \"rel_change_pct\": [div_rel[c] for c in COLS],\n",
    "    })\n",
    "    div_df.to_csv(out_divcsv, index=False)\n",
    "\n",
    "    stats_txt = STATS_DIR / \"spearman_and_monotonicity.txt\"\n",
    "    with open(stats_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Spearman ρ between AvgDiv and ΔRRMSE (baseline − full)\\n\")\n",
    "        f.write(f\"  • Linear (chain_lr + local_lasso):    rho = {rho_lin:.3f}, p = {p_lin:.3g}\\n\")\n",
    "        f.write(f\"  • Tree-based (local_rf + global_rf + chain_rf): rho = {rho_tree:.3f}, p = {p_tree:.3g}\\n\\n\")\n",
    "        f.write(\"Monotonicity check for AvgDiv (non-decreasing): \")\n",
    "        if ok:\n",
    "            f.write(\"PASS across [0,10,20,50,100,200,400].\\n\")\n",
    "        else:\n",
    "            bad_at = COLS[idx] if idx is not None else None\n",
    "            f.write(f\"FAIL (first decrease at column % = {bad_at}).\\n\")\n",
    "\n",
    "    # Print full report to console as well\n",
    "    import pandas as _pd\n",
    "    _pd.set_option(\"display.max_columns\", None)\n",
    "    _pd.set_option(\"display.width\", 140)\n",
    "\n",
    "    def _fmt_numeric_cols(df):\n",
    "        df2 = df.copy()\n",
    "        for c in COLS:\n",
    "            # Keep diversity row strings intact\n",
    "            if c in df2.columns and _pd.api.types.is_numeric_dtype(df2[c]):\n",
    "                df2[c] = df2[c].map(lambda x: f\"{x:.3f}\")\n",
    "        return df2\n",
    "\n",
    "    # Also print to screen in the requested order/format\n",
    "    def _df_console_str(df: pd.DataFrame) -> str:\n",
    "        df_print = df.copy()\n",
    "        # format RRMSE cells (all rows except the last diversity row)\n",
    "        for i in range(len(df_print) - 1):\n",
    "            for c in COLS:\n",
    "                df_print.at[i, c] = f\"{float(df_print.at[i, c]):.3f}\"\n",
    "        return df_print.to_string(index=False)\n",
    "\n",
    "    print(\"\\nLinear models (chain_lr, local_lasso)\")\n",
    "    print(_df_console_str(df_linear))\n",
    "    print(f\"Spearman \\u03c1 (AvgDiv vs \\u0394RRMSE), linear: rho = {rho_lin:.3f}, p = {p_lin:.3g}\\n\")\n",
    "\n",
    "    print(\"Tree-based models (local_rf, global_rf, chain_rf)\")\n",
    "    print(_df_console_str(df_tree))\n",
    "    print(f\"Spearman \\u03c1 (AvgDiv vs \\u0394RRMSE), tree-based: rho = {rho_tree:.3f}, p = {p_tree:.3g}\\n\")\n",
    "\n",
    "    # Monotonicity check printed last\n",
    "    if ok:\n",
    "        print(\"Monotonicity check for AvgDiv: PASS across [0, 10, 20, 50, 100, 200, 400].\")\n",
    "    else:\n",
    "        bad_at = COLS[idx] if idx is not None else None\n",
    "        print(f\"Monotonicity check for AvgDiv: FAIL (first decrease at %= {bad_at}).\")\n",
    "\n",
    "    log.info(\"=== f_5_average_diversity completed ===\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f87e046-7ff0-4526-9342-db887226fa5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kr8cht_review_anonymous",
   "language": "python",
   "name": "kr8cht_review_anonymous"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
