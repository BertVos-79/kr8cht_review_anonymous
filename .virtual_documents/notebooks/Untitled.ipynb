"""
r_1_overall_leaderboard.ipynb
───────────────────────────────────────────────────────────────────────────────
Unified leaderboard & breakdowns across steps (a_static, b_frozen, d_fine_tuned,
e_3_student_scoring). Builds a normalized long-form table, computes *global medians*
(↳ median over all folds × targets), and writes ranked leaderboards + per-family
and per-augmentation slices. Also prints a Top-20 summary to screen.

This notebook is *read-only over artifacts* and does not retrain anything.

This notebook:
1) Discovers artifacts
   - Baseline static:  outputs/a_static/results/baseline_{word2vec|fasttext}_loocv_rrmse.npy
   - Frozen:           outputs/b_frozen/results/{embedding}_loocv_rrmse.npy
   - Fine-tuned LoRA:  outputs/d_fine_tuned/results/partial_ft_{encoderid}_loocv_rrmse.npy
   - Augmented (students): outputs/e_3_student_scoring/results/rrmse_perfold_{student}__{reg}__{method}__pct{P}_K{K}__Mmax{M}__{baseline|full}.csv

2) Normalizes to a long table
   Columns:
   - source_step ∈ {a_static,b_frozen,d_fine_tuned,e_3_student_scoring}
   - family ∈ {static+MTR, frozen token mean+MTR, frozen token max+MTR,
               frozen token cls+MTR, frozen sentence+MTR, fine-tuned LoRA,
               augmented+<one of the above families>}
   - encoder (embedding / encoder alias)
   - pooling ∈ {'-','mean','max','cls','sentence'} (best-effort for frozen)
   - model (MTR model; for fine-tuned use literal 'fine-tuned')
   - augmentation ∈ {'NA','A10','A20','A50','A100','A200','A400'}
   - rrmse_median (global median over folds×targets)

3) Ranks & exports
   - Writes `reports/r_1_overall_leaderboard/leaderboard_full.csv`
   - Writes `reports/r_1_overall_leaderboard/leaderboard_top20.csv` (deterministic)
   - Writes per-family CSVs under `reports/r_1_overall_leaderboard/by_family/`
   - Writes augmentation slices under `reports/r_1_overall_leaderboard/by_family/augmented/A*.csv`
   - Saves small overview plots under `reports/r_1_overall_leaderboard/figs/`

4) Prints
   - Top-20 table in the notebook output
   - Brief distribution summaries

Tie-breaks (deterministic):
  1) rrmse_median (ascending) →
  2) family order: [static+MTR, frozen token mean+MTR, frozen token max+MTR,
                    frozen token cls+MTR, frozen sentence+MTR, fine-tuned LoRA,
                    augmented+…] →
  3) encoder (A→Z) →
  4) model (A→Z) →
  5) augmentation order: NA, A10, A20, A50, A100, A200, A400

Inputs (artifacts only):
- outputs/a_static/results/baseline_{embedding}_loocv_rrmse.npy
- outputs/b_frozen/results/{embedding}_loocv_rrmse.npy
- outputs/d_fine_tuned/results/partial_ft_{encoderid}_loocv_rrmse.npy
- outputs/e_3_student_scoring/results/rrmse_perfold_*__{baseline|full}.csv

Outputs (this notebook):
- reports/r_1_overall_leaderboard/leaderboard_full.csv
- reports/r_1_overall_leaderboard/leaderboard_top20.csv
- reports/r_1_overall_leaderboard/by_family/*.csv
- reports/r_1_overall_leaderboard/by_family/augmented/A{10,20,50,100,200,400}.csv
- reports/r_1_overall_leaderboard/figs/dist_overview.png
- reports/r_1_overall_leaderboard/figs/per_family_boxplots.png
"""

# ────────────────────────────────────────────
# Imports
# ────────────────────────────────────────────

import os
import re
import sys
import glob
import time
import warnings
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# keep look-and-feel consistent with your other notebooks
plt.rcParams.update({
    "figure.max_open_warning": 0,
    "axes.spines.top": False,
    "axes.spines.right": False,
    "font.size": 10,
})

# ────────────────────────────────────────────
# Paths
# ────────────────────────────────────────────
def get_project_root(marker: str = "LICENSE") -> Path:
    """Walk up from CWD to find repo root (file marker present)."""
    cwd = Path.cwd().resolve()
    for cand in (cwd, *cwd.parents):
        if (cand / marker).is_file():
            return cand
    return cwd

ROOT        = get_project_root()
OUTPUTS_DIR = ROOT / "outputs"
REPORTS_DIR = ROOT / "reports" / "r_1_overall_leaderboard"
REPORTS_DIR.mkdir(parents=True, exist_ok=True)
(REPORTS_DIR / "by_family" / "augmented").mkdir(parents=True, exist_ok=True)
(REPORTS_DIR / "figs").mkdir(parents=True, exist_ok=True)
SCRIPTS_DIR = REPORTS_DIR / "scripts"
SCRIPTS_DIR.mkdir(parents=True, exist_ok=True)

print(f"[INFO] Project root set to: {ROOT}")

# Source result roots
A_STATIC_DIR  = OUTPUTS_DIR / "a_static" / "results"
B_FROZEN_DIR  = OUTPUTS_DIR / "b_frozen" / "results"
D_FINETUNE_DIR= OUTPUTS_DIR / "d_fine_tuned" / "results"
E3_RESULTS_DIR= OUTPUTS_DIR / "e_3_student_scoring" / "results"

# ────────────────────────────────────────────
# Global configuration
# ────────────────────────────────────────────

# Family order for deterministic sorting
FAMILY_ORDER = [
    "static+MTR",
    "frozen token mean+MTR",
    "frozen token max+MTR",
    "frozen token cls+MTR",
    "frozen sentence+MTR",
    "fine-tuned LoRA",
    # any augmented+… families will be ranked after non-augmented families
]

AUG_ORDER = ["NA", "A10", "A20", "A50", "A100", "A200", "A400"]

warnings.simplefilter("ignore", category=FutureWarning)

# ──────────────────────────────────────────────────────────────
# 0. Print helpers
# ──────────────────────────────────────────────────────────────
def section(title: str):
    bar = "═" * len(title)
    print(f"\n{bar}\n{title}\n{bar}")

# ──────────────────────────────────────────────────────────────
# 1. Artifact loaders (re-using your style)
# ──────────────────────────────────────────────────────────────

def _load_rrmse_artifact_dict(npy_path: Path) -> Dict[str, np.ndarray]:
    """
    Load npy saved as dict {model_name -> (folds x targets) array}.
    """
    arr = np.load(npy_path, allow_pickle=True)
    try:
        d = arr.item()
        if isinstance(d, dict):
            return d
    except Exception:
        pass
    raise ValueError(f"Unexpected dict artifact format in {npy_path}")

def _load_rrmse_array_unknown(npy_path: Path) -> np.ndarray:
    """
    Robust loader for fine-tuned artifacts that may be saved either as:
      - raw ndarray of shape (folds, targets)
      - object npy containing a dict with key 'rrmse' or similar
    Returns an ndarray suitable for global median.
    """
    obj = np.load(npy_path, allow_pickle=True)
    # plain ndarray
    if isinstance(obj, np.ndarray) and obj.dtype != object:
        return np.asarray(obj)
    # object-ndarray holding dict
    try:
        d = obj.item()
        if isinstance(d, dict):
            # prefer 'rrmse' if present, else first ndarray value
            if "rrmse" in d:
                return np.asarray(d["rrmse"])
            for v in d.values():
                if isinstance(v, (np.ndarray, list, tuple)):
                    return np.asarray(v)
    except Exception:
        pass
    raise ValueError(f"Cannot extract RRMSE array from {npy_path}")

# ──────────────────────────────────────────────────────────────
# 2. Aggregation: *global* median (folds × targets)
# ──────────────────────────────────────────────────────────────
def global_median_from_array(mat: np.ndarray) -> float:
    return float(np.median(np.asarray(mat).astype(float)))

def global_median_from_dict(rrmse_dict: Dict[str, np.ndarray]) -> Dict[str, float]:
    return {k: global_median_from_array(v) for k, v in rrmse_dict.items()}

# ──────────────────────────────────────────────────────────────
# 3. Family & parsing utilities
# ──────────────────────────────────────────────────────────────

_POOL_RE  = re.compile(r"__(mean|max|cls)$")
_SENT_HINT = ("sbert", "e5", "labse", "simcse", "paraphrase", "sentence")

def family_from_embedding_name(embedding: str, default_family="frozen sentence+MTR") -> Tuple[str, str]:
    """
    Best-effort mapping from embedding name to (family, pooling).
    - If suffix `__mean|__max|__cls` → token-pooling families.
    - Else if name hints sentence embedding → sentence family.
    - Else default to sentence family (conservative).
    """
    m = _POOL_RE.search(embedding)
    if m:
        pool = m.group(1)
        return (f"frozen token {pool}+MTR", pool)
    low = embedding.lower()
    if any(h in low for h in _SENT_HINT):
        return ("frozen sentence+MTR", "sentence")
    return (default_family, "sentence")

def family_sort_key(fam: str) -> int:
    # augmented+… come after all base families; preserve base order inside augmented by stripping prefix.
    if fam.startswith("augmented+"):
        base = fam.split("+", 1)[1]
        return 100 + FAMILY_ORDER.index(base) if base in FAMILY_ORDER else 199
    return FAMILY_ORDER.index(fam) if fam in FAMILY_ORDER else 198

def augmentation_label_from_parts(variant: str, pct: str|None) -> str:
    if variant == "baseline" or not pct:
        return "NA"
    return f"A{pct}"

def augmentation_sort_key(a: str) -> int:
    return AUG_ORDER.index(a) if a in AUG_ORDER else len(AUG_ORDER) + 1

# ──────────────────────────────────────────────────────────────
# 4. Collectors per step
# ──────────────────────────────────────────────────────────────

def collect_a_static_rows() -> List[dict]:
    rows = []
    for npy in sorted(A_STATIC_DIR.glob("baseline_*_loocv_rrmse.npy")):
        emb = npy.stem.replace("baseline_", "").replace("_loocv_rrmse", "")
        try:
            d = _load_rrmse_artifact_dict(npy)
        except Exception as e:
            print(f"[WARN] Skipping {npy.name}: {e}")
            continue
        med = global_median_from_dict(d)
        for model_name, rmed in med.items():
            rows.append({
                "source_step": "a_static",
                "family": "static+MTR",
                "encoder": emb,
                "pooling": "-",
                "model": model_name,
                "augmentation": "NA",
                "rrmse_median": rmed,
            })
    return rows

def collect_b_frozen_rows() -> List[dict]:
    rows = []
    for npy in sorted(B_FROZEN_DIR.glob("*_loocv_rrmse.npy")):
        emb_full = npy.stem.replace("_loocv_rrmse", "")
        try:
            d = _load_rrmse_artifact_dict(npy)
        except Exception as e:
            print(f"[WARN] Skipping {npy.name}: {e}")
            continue
        fam, pooling = family_from_embedding_name(emb_full)
        # encoder: strip pooling suffix for readability
        encoder = _POOL_RE.sub("", emb_full)
        med = global_median_from_dict(d)
        for model_name, rmed in med.items():
            rows.append({
                "source_step": "b_frozen",
                "family": fam,
                "encoder": encoder,
                "pooling": pooling,
                "model": model_name,
                "augmentation": "NA",
                "rrmse_median": rmed,
            })
    return rows

def collect_d_finetuned_rows() -> List[dict]:
    rows = []
    for npy in sorted(D_FINETUNE_DIR.glob("partial_ft_*_loocv_rrmse.npy")):
        # partial_ft_{encoderid}_loocv_rrmse.npy → encoderid
        stem = npy.stem
        enc = stem[len("partial_ft_") : -len("_loocv_rrmse")]
        try:
            arr = _load_rrmse_array_unknown(npy)
        except Exception as e:
            print(f"[WARN] Skipping {npy.name}: {e}")
            continue
        rmed = global_median_from_array(arr)
        rows.append({
            "source_step": "d_fine_tuned",
            "family": "fine-tuned LoRA",
            "encoder": enc,
            "pooling": "sentence",
            "model": "fine-tuned",
            "augmentation": "NA",
            "rrmse_median": rmed,
        })
    return rows

_E3_RE = re.compile(
    r"^rrmse_perfold_(?P<encoder>[^_]+)__(?P<model>[^_]+)__(?P<method>[^_]+)__pct(?P<pct>\d+)_K(?P<K>\d+)__Mmax(?P<Mmax>\d+)__(?P<variant>baseline|full)\.csv$"
)

def collect_e3_rows() -> List[dict]:
    rows = []
    for csv_path in sorted(E3_RESULTS_DIR.glob("rrmse_perfold_*__*.csv")):
        m = _E3_RE.match(csv_path.name)
        if not m:
            # older legacy names (n-based); you can extend here if you need to parse them too
            continue
        gd = m.groupdict()
        encoder  = gd["encoder"]
        model    = gd["model"]
        pct      = gd["pct"]
        variant  = gd["variant"]

        # read CSV and compute global median over numeric cells (folds×targets)
        try:
            df = pd.read_csv(csv_path)
        except Exception as e:
            print(f"[WARN] Skipping {csv_path.name}: {e}")
            continue

        numeric = df.select_dtypes(include=[np.number]).values
        if numeric.size == 0:
            print(f"[WARN] No numeric data in {csv_path.name}; skipping.")
            continue

        rmed = float(np.median(numeric.astype(float)))

        # map family from encoder; prefix with augmented+ if variant=full
        base_family, pooling = family_from_embedding_name(encoder)
        fam = base_family if variant == "baseline" else f"augmented+{base_family}"
        aug = augmentation_label_from_parts(variant, pct)

        rows.append({
            "source_step": "e_3_student_scoring",
            "family": fam,
            "encoder": encoder,
            "pooling": pooling,
            "model": model,               # student regressor
            "augmentation": aug,          # NA or A*
            "rrmse_median": rmed,
        })
    return rows

# ──────────────────────────────────────────────────────────────
# 5. Build normalized table & leaderboards
# ──────────────────────────────────────────────────────────────

def build_normalized_table() -> pd.DataFrame:
    section("Collecting artifacts into a normalized table")
    rows = []
    rows += collect_a_static_rows()
    rows += collect_b_frozen_rows()
    rows += collect_d_finetuned_rows()
    rows += collect_e3_rows()

    df = pd.DataFrame(rows, columns=[
        "source_step","family","encoder","pooling","model","augmentation","rrmse_median"
    ]).dropna(subset=["rrmse_median"])

    if df.empty:
        raise RuntimeError("No rows collected. Ensure artifacts exist under outputs/* as documented.")

    print(f"[INFO] Collected rows: {len(df)}")
    return df

def sort_leaderboard(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["family_ord"] = df["family"].apply(family_sort_key)
    df["aug_ord"]    = df["augmentation"].apply(augmentation_sort_key)
    df_sorted = df.sort_values(
        by=["rrmse_median","family_ord","encoder","model","aug_ord"],
        ascending=[True, True, True, True, True]
    ).drop(columns=["family_ord","aug_ord"])
    return df_sorted

def write_reports(df_norm: pd.DataFrame):
    # Full leaderboard
    full = sort_leaderboard(df_norm)
    full_path = REPORTS_DIR / "leaderboard_full.csv"
    full.to_csv(full_path, index=False)
    print(f"[SAVE] → {full_path}  ({len(full)} rows)")

    # Top-20
    top20 = full.head(20).copy()
    top20.insert(0, "rank", range(1, len(top20) + 1))
    top_path = REPORTS_DIR / "leaderboard_top20.csv"
    top20.to_csv(top_path, index=False)
    print(f"[SAVE] → {top_path}")

    # Print Top-20 nicely
    section("Top-20 Leaderboard (printed)")
    print(top20[["rank","encoder","model","augmentation","rrmse_median","family"]].to_string(index=False, formatters={
        "rrmse_median": lambda x: f"{x:.3f}"
    }))

    # By family
    fam_dir = REPORTS_DIR / "by_family"
    fam_dir.mkdir(exist_ok=True, parents=True)
    for fam in sorted(df_norm["family"].unique(), key=family_sort_key):
        sub = sort_leaderboard(df_norm[df_norm["family"] == fam])
        out = fam_dir / (fam.replace(" ", "_").replace("+","_plus_") + ".csv")
        sub.to_csv(out, index=False)
        print(f"[SAVE] → {out}  ({len(sub)} rows)")

    # Augmented slices
    aug_dir = fam_dir / "augmented"
    aug_dir.mkdir(exist_ok=True, parents=True)
    aug_sub = df_norm[df_norm["augmentation"] != "NA"].copy()
    for a in AUG_ORDER[1:]:  # skip NA
        sub = sort_leaderboard(aug_sub[aug_sub["augmentation"] == a])
        out = aug_dir / f"{a}.csv"
        sub.to_csv(out, index=False)
        print(f"[SAVE] → {out}  ({len(sub)} rows)")

# ──────────────────────────────────────────────────────────────
# 6. Small overview plots (optional but helpful)
# ──────────────────────────────────────────────────────────────

def plot_overview(df_norm: pd.DataFrame):
    section("Overview plots")

    # Distribution overall
    fig, ax = plt.subplots(figsize=(6,3.5), dpi=120)
    ax.hist(df_norm["rrmse_median"].values, bins=30)
    ax.set_title("Distribution of global median RRMSE (all configs)")
    ax.set_xlabel("global median RRMSE (↓ better)")
    ax.set_ylabel("count")
    fig.savefig(REPORTS_DIR / "figs" / "dist_overview.png", bbox_inches="tight", dpi=300)
    plt.show()
    print("[SAVE] → figs/dist_overview.png")

    # Per-family boxplot
    fams = sorted(df_norm["family"].unique(), key=family_sort_key)
    data = [df_norm[df_norm["family"] == f]["rrmse_median"].values for f in fams]
    fig, ax = plt.subplots(figsize=(8,3.5), dpi=120)
    ax.boxplot(data, labels=fams, showfliers=False)
    ax.set_title("Per-family global median RRMSE")
    ax.set_ylabel("global median RRMSE (↓)")
    ax.set_xticklabels(ax.get_xticklabels(), rotation=15, ha="right")
    fig.savefig(REPORTS_DIR / "figs" / "per_family_boxplots.png", bbox_inches="tight", dpi=300)
    plt.show()
    print("[SAVE] → figs/per_family_boxplots.png")

# ────────────────────────────────────────────
# 7. Entry-point
# ────────────────────────────────────────────

if __name__ == "__main__":
    start = time.time()
    try:
        df_norm = build_normalized_table()
        write_reports(df_norm)
        plot_overview(df_norm)
    except Exception as e:
        print(f"[ERROR] {e}")
    end = time.time()
    print(f"Total execution time: {end-start:.1f} s")




